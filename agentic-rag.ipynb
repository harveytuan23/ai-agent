{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e1fbb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Load the dataset\n",
    "guest_dataset = datasets.load_dataset(\"agents-course/unit3-invitees\", split=\"train\")\n",
    "\n",
    "# Convert dataset entries into Document objects\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"\\n\".join([\n",
    "            f\"Name: {guest['name']}\",\n",
    "            f\"Relation: {guest['relation']}\",\n",
    "            f\"Description: {guest['description']}\",\n",
    "            f\"Email: {guest['email']}\"\n",
    "        ]),\n",
    "        metadata={\"name\": guest[\"name\"]}\n",
    "    )\n",
    "    for guest in guest_dataset\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fecd600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.tools import Tool\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(docs)\n",
    "\n",
    "def extract_text(query: str) -> str:\n",
    "    \"\"\"Retrieves detailed information about gala guests based on their name or relation.\"\"\"\n",
    "    results = bm25_retriever.invoke(query)\n",
    "    if results:\n",
    "        return \"\\n\\n\".join([doc.page_content for doc in results[:3]])\n",
    "    else:\n",
    "        return \"No matching guest information found.\"\n",
    "\n",
    "guest_info_tool = Tool(\n",
    "    name=\"guest_info_retriever\",\n",
    "    func=extract_text,\n",
    "    description=\"Retrieves detailed information about gala guests based on their name or relation.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed68d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ© Alfred's Response:\n",
      "Lady Ada Lovelace is my best friend. She is renowned for her pioneering work in mathematics and computing, often celebrated as the first computer programmer due to her work on Charles Babbage's Analytical Engine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import AnyMessage, HumanMessage, AIMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "SYSTEM_POLICY = \"\"\"You are Alfred, a gala assistant.\n",
    "If the user asks about a guest by name or relation, first call the tool to retrieve info.\n",
    "Then answer with ONE natural sentence using ONLY the tool result.\n",
    "You don't say exactly same as the tool result, use your own words.\n",
    "If not found, reply exactly: No matching guest information found.\n",
    "No bullets, no headings, no extra text. Keep it concise and in the user's language.\n",
    "\"\"\" \n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Generate the chat interface, including the tools\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"Qwen/Qwen2.5-Coder-32B-Instruct\",\n",
    "    huggingfacehub_api_token=os.getenv(\"HUGGINGFACE_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat = ChatHuggingFace(llm=llm, verbose=True)\n",
    "tools = [guest_info_tool]\n",
    "chat_with_tools = chat.bind_tools(tools)\n",
    "\n",
    "# Generate the AgentState and Agent graph\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "def assistant(state: AgentState):\n",
    "    msgs = [SystemMessage(content=SYSTEM_POLICY)] + state[\"messages\"]\n",
    "    return {\n",
    "        \"messages\": [chat_with_tools.invoke(msgs)],\n",
    "    }\n",
    "\n",
    "## The graph\n",
    "builder = StateGraph(AgentState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message requires a tool, route to tools\n",
    "    # Otherwise, provide a direct response\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "alfred = builder.compile()\n",
    "\n",
    "messages = [HumanMessage(content=\"Tell me about our guest named 'Lady Ada Lovelace'.\")]\n",
    "response = alfred.invoke({\"messages\": messages})\n",
    "\n",
    "print(\"ðŸŽ© Alfred's Response:\")\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b54817",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "\n",
    "langfuse = Langfuse(\n",
    "  secret_key=os.getenv(\"LANGFUSE_SECRET_KEY\"),\n",
    "  public_key=os.getenv(\"LANGFUSE_PUBLIC_KEY\"),\n",
    "  host=os.getenv(\"LANGFUSE_HOST\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cebf5dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Langfuse was not able to parse the LLM model. The LLM call will be recorded without model name. Please create an issue: https://github.com/langfuse/langfuse/issues/new/choose\n"
     ]
    }
   ],
   "source": [
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# Initialize Langfuse CallbackHandler for LangGraph/Langchain (tracing)\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "# Process legitimate email\n",
    "response = alfred.invoke(\n",
    "    input={\"messages\": messages},\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    ")\n",
    "\n",
    "# compiled_graph.invoke(\n",
    "#     input={\"email\": spam_email, \"is_spam\": None, \"spam_reason\": None, \"email_category\": None, \"draft_response\": None, \"messages\": []},\n",
    "#     config={\"callbacks\": [langfuse_handler]}\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
