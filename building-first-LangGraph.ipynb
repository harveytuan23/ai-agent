{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28345778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, List, Dict, Any, Optional\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1678bae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailState(TypedDict):\n",
    "    # The email being processed\n",
    "    email: Dict[str, Any]  # Contains subject, sender, body, etc.\n",
    "\n",
    "    # Category of the email (inquiry, complaint, etc.)\n",
    "    email_category: Optional[str]\n",
    "\n",
    "    # Reason why the email was marked as spam\n",
    "    spam_reason: Optional[str]\n",
    "\n",
    "    # Analysis and decisions\n",
    "    is_spam: Optional[bool]\n",
    "    \n",
    "    # Response generation\n",
    "    email_draft: Optional[str]\n",
    "    \n",
    "    # Processing metadata\n",
    "    messages: List[Dict[str, Any]]  # Track conversation with LLM for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4847c941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our LLM with Groq\n",
    "# You need to set your GROQ_API_KEY environment variable\n",
    "# export GROQ_API_KEY=\"your-groq-api-key-here\"\n",
    "\n",
    "# Initialize the Groq model\n",
    "model = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",  # You can change this to other Groq models\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "def read_email(state: EmailState):\n",
    "    \"\"\"Alfred reads and logs the incoming email\"\"\"\n",
    "    email = state[\"email\"]\n",
    "    \n",
    "    # Here we might do some initial preprocessing\n",
    "    print(f\"Alfred is processing an email from {email['sender']} with subject: {email['subject']}\")\n",
    "    \n",
    "    # No state changes needed here\n",
    "    return {}\n",
    "\n",
    "def _parse_json_payload(text: str) -> dict:\n",
    "    # 兼容 ```json ... ``` 或 ``` ... ```；抓第一個花括號區塊\n",
    "    m = re.search(r\"```(?:json)?\\s*(\\{.*?\\})\\s*```\", text, flags=re.S)\n",
    "    payload = m.group(1) if m else text.strip()\n",
    "    return json.loads(payload)\n",
    "\n",
    "def _normalize_email_state(state: Dict[str, Any]) -> None:\n",
    "    \"\"\"一致性保護：垃圾信必有 reason，合法信 reason 必為 None。\"\"\"\n",
    "    if state.get(\"is_spam\"):\n",
    "        if not state.get(\"spam_reason\") or str(state[\"spam_reason\"]).strip() == \"\":\n",
    "            state[\"spam_reason\"] = \"Flagged by classifier (missing reason)\"\n",
    "        state[\"email_category\"] = None\n",
    "    else:\n",
    "        state[\"spam_reason\"] = None\n",
    "        # 合法信 category 可留白或限定白名單\n",
    "        if state.get(\"email_category\") not in [\"inquiry\",\"complaint\",\"thank you\",\"request\",\"information\", None]:\n",
    "            state[\"email_category\"] = None\n",
    "\n",
    "def classify_email(state: EmailState):\n",
    "    \"\"\"Alfred uses an LLM to determine if the email is spam or legitimate\"\"\"\n",
    "    email = state[\"email\"]\n",
    "    \n",
    "    # Prepare our prompt for the LLM\n",
    "    prompt = f\"\"\"\n",
    "    As Alfred the butler, analyze this email and determine if it is spam or legitimate.\n",
    "    \n",
    "    Email:\n",
    "    From: {email['sender']}\n",
    "    Subject: {email['subject']}\n",
    "    Body: {email['body']}\n",
    "    \n",
    "    You are Alfred the butler. Analyze the email and return ONLY a compact JSON object with keys:\n",
    "    - is_spam: boolean\n",
    "    - spam_reason: string or null\n",
    "    - category: one of [\"inquiry\",\"complaint\",\"thank you\",\"request\",\"information\",null]\n",
    "\n",
    "    Rules:\n",
    "    - If legitimate, set is_spam=false and category accordingly; spam_reason must be null.\n",
    "    - If spam, set is_spam=true and provide a concise spam_reason; category must be null.\n",
    "    - Do not include any extra text.\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    response = model.invoke(messages)\n",
    "    raw = response.content.strip()\n",
    "\n",
    "    response_text = response.content.lower()\n",
    "    is_spam = \"spam\" in response_text and \"not spam\" not in response_text\n",
    "    \n",
    "    spam_reason = None\n",
    "    if is_spam and \"reason:\" in response_text:\n",
    "        spam_reason = response_text.split(\"reason:\")[1].strip()\n",
    "\n",
    "    # 兼容：有些模型會用 code fence，把它剝掉\n",
    "    if raw.startswith(\"```\"):\n",
    "        raw = raw.strip(\"`\")\n",
    "        # 可能是 \"json\\n{...}\"\n",
    "        if raw.startswith(\"json\"):\n",
    "            raw = raw[4:].strip()\n",
    "\n",
    "    data = {}\n",
    "    try:\n",
    "        data = json.loads(raw)\n",
    "        print(f\"Data = {data}\")\n",
    "    except Exception:\n",
    "        # 後備：退化為舊的關鍵字法，但盡量降低誤判\n",
    "        lower = response.content.lower()\n",
    "        is_spam = (\"spam\" in lower and \"not spam\" not in lower and \"legitimate\" not in lower and \"likely legitimate\" not in lower)\n",
    "        category = None\n",
    "        if not is_spam:\n",
    "            for c in [\"inquiry\",\"complaint\",\"thank you\",\"request\",\"information\"]:\n",
    "                if c in lower:\n",
    "                    category = c\n",
    "                    break\n",
    "        data = {\n",
    "            \"is_spam\": bool(is_spam),\n",
    "            \"spam_reason\": \"Heuristic fallback (no JSON from model)\" if is_spam else None,\n",
    "            \"category\": category if not is_spam else None,\n",
    "        }\n",
    "\n",
    "    # 一致性保護：避免 None/矛盾狀態\n",
    "    is_spam = bool(data.get(\"is_spam\", False))\n",
    "    spam_reason = data.get(\"spam_reason\")\n",
    "    category = data.get(\"category\")\n",
    "\n",
    "    if is_spam:\n",
    "        # 垃圾信時必須有原因\n",
    "        if not spam_reason or str(spam_reason).strip() == \"\":\n",
    "            spam_reason = \"Flagged by policy/rules (missing reason from model)\"\n",
    "        category = None\n",
    "    else:\n",
    "        spam_reason = None\n",
    "        if category not in [\"inquiry\",\"complaint\",\"thank you\",\"request\",\"information\", None]:\n",
    "            category = None  # 清理不在白名單的類別\n",
    "\n",
    "    new_messages = state.get(\"messages\", []) + [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": response.content}\n",
    "    ]\n",
    "\n",
    "    return {\n",
    "        \"is_spam\": is_spam,\n",
    "        \"spam_reason\": spam_reason,\n",
    "        \"email_category\": category,\n",
    "        \"messages\": new_messages\n",
    "    }\n",
    "\n",
    "def handle_spam(state: EmailState):\n",
    "    \"\"\"Alfred discards spam email with a note\"\"\"\n",
    "    print(f\"Alfred has marked the email as spam. Reason: {state['spam_reason']}\")\n",
    "    print(\"The email has been moved to the spam folder.\")\n",
    "    \n",
    "    # We're done processing this email\n",
    "    return {}\n",
    "\n",
    "def draft_response(state: EmailState):\n",
    "    \"\"\"Alfred drafts a preliminary response for legitimate emails\"\"\"\n",
    "    email = state[\"email\"]\n",
    "    category = state[\"email_category\"] or \"general\"\n",
    "    \n",
    "    # Prepare our prompt for the LLM\n",
    "    prompt = f\"\"\"\n",
    "    As Alfred the butler, draft a polite preliminary response to this email.\n",
    "    \n",
    "    Email:\n",
    "    From: {email['sender']}\n",
    "    Subject: {email['subject']}\n",
    "    Body: {email['body']}\n",
    "    \n",
    "    This email has been categorized as: {category}\n",
    "    \n",
    "    Draft a brief, professional response that Mr. Hugg can review and personalize before sending.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Call the LLM\n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Update messages for tracking\n",
    "    new_messages = state.get(\"messages\", []) + [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": response.content}\n",
    "    ]\n",
    "    \n",
    "    # Return state updates\n",
    "    return {\n",
    "        \"email_draft\": response.content,\n",
    "        \"messages\": new_messages\n",
    "    }\n",
    "\n",
    "def notify_mr_hugg(state: EmailState):\n",
    "    \"\"\"Alfred notifies Mr. Hugg about the email and presents the draft response\"\"\"\n",
    "    email = state[\"email\"]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Sir, you've received an email from {email['sender']}.\")\n",
    "    print(f\"Subject: {email['subject']}\")\n",
    "    print(f\"Category: {state['email_category']}\")\n",
    "    print(\"\\nI've prepared a draft response for your review:\")\n",
    "    print(\"-\"*50)\n",
    "    print(state[\"email_draft\"])\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    # We're done processing this email\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4d606f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_email(state: EmailState) -> str:\n",
    "    \"\"\"Determine the next step based on spam classification\"\"\"\n",
    "    if state[\"is_spam\"]:\n",
    "        return \"spam\"\n",
    "    else:\n",
    "        return \"legitimate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "41bb5785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph\n",
    "email_graph = StateGraph(EmailState)\n",
    "\n",
    "# Add nodes\n",
    "email_graph.add_node(\"read_email\", read_email)\n",
    "email_graph.add_node(\"classify_email\", classify_email)\n",
    "email_graph.add_node(\"handle_spam\", handle_spam)\n",
    "email_graph.add_node(\"draft_response\", draft_response)\n",
    "email_graph.add_node(\"notify_mr_hugg\", notify_mr_hugg)\n",
    "\n",
    "# Start the edges\n",
    "email_graph.add_edge(START, \"read_email\")\n",
    "# Add edges - defining the flow\n",
    "email_graph.add_edge(\"read_email\", \"classify_email\")\n",
    "\n",
    "# Add conditional branching from classify_email\n",
    "email_graph.add_conditional_edges(\n",
    "    \"classify_email\",\n",
    "    route_email,\n",
    "    {\n",
    "        \"spam\": \"handle_spam\",\n",
    "        \"legitimate\": \"draft_response\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add the final edges\n",
    "email_graph.add_edge(\"handle_spam\", END)\n",
    "email_graph.add_edge(\"draft_response\", \"notify_mr_hugg\")\n",
    "email_graph.add_edge(\"notify_mr_hugg\", END)\n",
    "\n",
    "# Compile the graph\n",
    "compiled_graph = email_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9712054c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing legitimate email...\n",
      "Alfred is processing an email from john.smith@example.com with subject: Question about your services\n",
      "\n",
      "==================================================\n",
      "Sir, you've received an email from john.smith@example.com.\n",
      "Subject: Question about your services\n",
      "Category: inquiry\n",
      "\n",
      "I've prepared a draft response for your review:\n",
      "--------------------------------------------------\n",
      "Here's a draft of a polite preliminary response:\n",
      "\n",
      "\"Dear Mr. Smith,\n",
      "\n",
      "Thank you for reaching out to me and for the referral from your colleague. I'm pleased to hear that you're interested in learning more about my consulting services. I'd be more than happy to schedule a call to discuss how I can assist you.\n",
      "\n",
      "Before we proceed, I'd like to confirm a few details. Could you please let me know what specific areas of consulting you're interested in learning more about? This will help me tailor our conversation to your needs.\n",
      "\n",
      "Once I have this information, I'll be in touch to schedule a call at your convenience.\n",
      "\n",
      "Best regards,\n",
      "Alfred (Mr. Hugg's Butler)\"\n",
      "\n",
      "This response acknowledges Mr. Smith's email, expresses gratitude for the referral, and politely requests more information to ensure a productive conversation.\n",
      "==================================================\n",
      "\n",
      "\n",
      "Processing spam email...\n",
      "Alfred is processing an email from winner@lottery-intl.com with subject: YOU HAVE WON $5,000,000!!!\n",
      "Alfred has marked the email as spam. Reason: Heuristic fallback (no JSON from model)\n",
      "The email has been moved to the spam folder.\n"
     ]
    }
   ],
   "source": [
    "# Example legitimate email\n",
    "legitimate_email = {\n",
    "    \"sender\": \"john.smith@example.com\",\n",
    "    \"subject\": \"Question about your services\",\n",
    "    \"body\": \"Dear Mr. Hugg, I was referred to you by a colleague and I'm interested in learning more about your consulting services. Could we schedule a call next week? Best regards, John Smith\"\n",
    "}\n",
    "\n",
    "# Example spam email\n",
    "spam_email = {\n",
    "    \"sender\": \"winner@lottery-intl.com\",\n",
    "    \"subject\": \"YOU HAVE WON $5,000,000!!!\",\n",
    "    \"body\": \"CONGRATULATIONS! You have been selected as the winner of our international lottery! To claim your $5,000,000 prize, please send us your bank details and a processing fee of $100.\"\n",
    "}\n",
    "\n",
    "# Process the legitimate email\n",
    "print(\"\\nProcessing legitimate email...\")\n",
    "legitimate_result = compiled_graph.invoke({\n",
    "    \"email\": legitimate_email,\n",
    "    \"is_spam\": None,\n",
    "    \"spam_reason\": None,\n",
    "    \"email_category\": None,\n",
    "    \"email_draft\": None,\n",
    "    \"messages\": []\n",
    "})\n",
    "\n",
    "# Process the spam email\n",
    "print(\"\\nProcessing spam email...\")\n",
    "spam_result = compiled_graph.invoke({\n",
    "    \"email\": spam_email,\n",
    "    \"is_spam\": None,\n",
    "    \"spam_reason\": None,\n",
    "    \"email_category\": None,\n",
    "    \"email_draft\": None,\n",
    "    \"messages\": []\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6937673c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse import Langfuse\n",
    "\n",
    "langfuse = Langfuse(\n",
    "  secret_key=\"sk-lf-d1d8310a-4266-4522-8ecc-b923320113a4\",\n",
    "  public_key=\"pk-lf-7085ff39-2153-4783-acac-731612dc20b8\",\n",
    "  host=\"https://us.cloud.langfuse.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4b4f5b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alfred is processing an email from winner@lottery-intl.com with subject: YOU HAVE WON $5,000,000!!!\n",
      "\n",
      "==================================================\n",
      "Sir, you've received an email from winner@lottery-intl.com.\n",
      "Subject: YOU HAVE WON $5,000,000!!!\n",
      "Category: None\n",
      "\n",
      "I've prepared a draft response for your review:\n",
      "--------------------------------------------------\n",
      "Here's a polite preliminary response to the email:\n",
      "\n",
      "Subject: Re: YOU HAVE WON $5,000,000!!!\n",
      "\n",
      "Dear Winner@lottery-intl.com,\n",
      "\n",
      "Thank you for your email informing Mr. Hugg of his alleged win in the international lottery. I must express some caution and request further clarification regarding this matter. As Mr. Hugg's butler, I am responsible for ensuring the security and integrity of his personal and financial information.\n",
      "\n",
      "Before proceeding, I would appreciate it if you could provide more information about your organization, such as your official website, contact details, and any relevant licenses or certifications. Additionally, I would like to know more about the processing fee and the verification process for claiming the prize.\n",
      "\n",
      "I look forward to hearing back from you and discussing this matter further.\n",
      "\n",
      "Best regards,\n",
      "Alfred, Butler to Mr. Hugg\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# Initialize Langfuse CallbackHandler for LangGraph/Langchain (tracing)\n",
    "langfuse_handler = CallbackHandler()\n",
    "\n",
    "# Process legitimate email\n",
    "legitimate_result = compiled_graph.invoke(\n",
    "    input={\"email\": spam_email, \"is_spam\": None, \"spam_reason\": None, \"email_category\": None, \"draft_response\": None, \"messages\": []},\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
